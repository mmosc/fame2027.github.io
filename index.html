<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>POLYSIM 2026 - Polyglot Speaker Identification with Missing Modality</title>
    <link rel="stylesheet" href="./static/css/styles.css">
    <style>
        /* Homepage-specific styles */
        .body-container {
            margin-top: 0;
        }

        .banner-container {
            height: 40vh;
            margin-top: 10vh;
        }

        @media (max-width: 900px) {
            .banner-container {
                height: 30vh;
            }
        }
    </style>
</head>
<body>

    <!-- Navbar -->
    <nav>
        <div>
            <a href="#home">Home</a>
            <a href="task.html">Task</a>
            <a href="resources.html">Resources</a>
            <a href="participate.html">Participate</a>
            <a href="references.html">References</a>
        </div>
    </nav>
    <!-- //////////////////////////////////////////////////////////////////////// -->


    <div class="body-container" id="home">
        <!-- banner -->
        <div class="banner-container">
            <div class="card-container">
                <p>
                    <span style="font-family: montserrat_bold;"> POLYSIM </span><br>
                    <span style="font-size: 14px;"> Polyglot Speaker Identification with Missing Modality </span>
                </p>
                <p></p>
            </div>
        </div>
        <!-- //////////////////////////////////////////////////////////////////////// -->

        <!-- Introduction -->
        <div class="descriptions" id="introduction">
            <p class="description-headings">Introduction</p>
            <p>
                <b>Can you identify a speaker across languages when you can't see their face? Or when you can't hear their voice?</b>
                The POLYSIM 2026 Challenge tackles this critical question in multimodal biometrics.
                <br><br>
                Recent years have seen significant advances in multimodal biometric systems that leverage both facial and
                vocal characteristics for speaker identification. However, real-world applications often face scenarios where
                one modality is unavailable due to technical constraints, privacy concerns, or environmental factors.
                <br><br>
                The POLYSIM 2026 Challenge addresses these real-world multimodal biometric scenarios where facial or vocal
                data may be unavailable. Participants will develop robust speaker identification systems that maintain
                accuracy across multiple languages (polyglot) even when face or voice modality is completely missing.
                This challenge simulates practical constraints in biometric systems, addressing the critical question:
                "Can speakers be accurately identified across multiple languages when only partial multimodal information is available?"
                <br><br>
                To support this research, we provide the Multilingual Audio-Visual (MAV-CELEB) dataset, containing
                human speech clips of 154 identities with multiple language annotations extracted from various videos uploaded
                online. The dataset enables investigation of speaker identification across languages while handling missing
                modality scenarios, addressing both the polyglot and incomplete data challenges that are prevalent in
                practical applications.
            </p>
        </div>
        <div class="figures">
            <img src="./static/images/homepage_task_diag.jpg">
            <p>
                Figure 1: Diagram showing multimodal speaker identification across multiple languages with missing modality scenarios.
            </p>
        </div>

        <!-- Quick Facts -->
        <div class="descriptions" id="quick-facts" style="background-color: var(--tertiary-color); padding-bottom: 2vh;">
            <p class="description-headings">Quick facts</p>
            <ul style="list-style: none; padding-left: 0;">
                <li>üìä <b>Dataset:</b> 154 identities across multiple languages</li>
                <li>üéØ <b>Task:</b> Speaker identification with missing modalities</li>
                <li>üìÖ <b>Timeline:</b> August 2026 - December 2026</li>
                <li>üèÜ <b>Venue:</b> ACM MM 2026 Grand Challenge</li>
                <li>üìà <b>Metric:</b> Equal Error Rate (EER)</li>
            </ul>
        </div>
        <!-- //////////////////////////////////////////////////////////////////////// -->

        <!-- Footer -->
        <div class="footer">

        </div>
    </div>
    

</body>
</html>
